{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb459e21",
   "metadata": {},
   "source": [
    "# Package Install\n",
    "The package installation section establishes the technological foundation through essential libraries: `numpy` enables efficient numerical array operations and mathematical computations fundamental to scientific computing; `pandas` facilitates structured data manipulation and tabular analysis with powerful DataFrame operations; `seaborn` and `matplotlib` provide statistical visualisations and graphical representations essential for exploratory data analysis and result communication; `scikit-learn` supplies machine learning algorithms, preprocessing utilities, and comprehensive model evaluation metrics; and `pyspark` enables distributed computing capabilities for processing large-scale datasets exceeding single-machine memory constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658612f",
   "metadata": {},
   "source": [
    "Uncomment the line that corresponds to your Kernel of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b956df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install numpy; pandas; seaborn; scikit-learn; matplotlib; pyspark; imblearn\n",
    "# %pip install numpy; pandas; seaborn; scikit-learn; matplotlib; pyspark; imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387ced7",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "The import statements are strategically organised by functional category to establish a comprehensive analytical toolkit. Core data processing leverages `pandas` for DataFrames and `numpy` for numerical computations. Visualisation frameworks encompass `matplotlib.pyplot` for customised plotting and `seaborn` for enhanced statistical graphics. Scikit-learn imports include `RobustScaler` for outlier-resilient feature standardisation, `train_test_split` for stratified dataset partitioning, `GridSearchCV` and `StratifiedKFold` for systematic hyperparameter optimisation and cross-validation, and comprehensive metrics including `confusion_matrix`, `classification_report`, individual scoring functions (`precision_score`, `recall_score`, `f1_score`, `accuracy_score`), and ROC analysis tools (`roc_curve`, `roc_auc_score`) for threshold-independent performance assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                            f1_score, roc_auc_score, roc_curve, \n",
    "                            precision_recall_curve, confusion_matrix, \n",
    "                            classification_report, average_precision_score)\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import product\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34637d6",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n",
    "Dataset: GoodReads 100k books (https://www.kaggle.com/datasets/mdhamani/goodreads-books-100k/data)\n",
    "\n",
    "The dataset loading process begins by defining target columns representing key book characteristics theoretically relevant for predicting bestseller status: `rating` (numerical quality score), `reviews` (engagement frequency), `pages` (book length), `totalratings` (popularity measure), and optional categorical fields (`genre`, `author`, `title`). The implementation starts by using Pyspark but it turns out that there is data corruption caused by Pyspark reading the data. Thus pandas is used with `pd.read_csv()` configured to selectively load columns via `usecols` parameter, optimising memory usage by excluding irrelevant fields during the read operation. This approach ensures data integrity and preserves correct field alignment, addressing limitations encountered with distributed processing frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d852bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and constants\n",
    "DATA_PATH = \"GoodReads_100k_books.csv\"\n",
    "RANDOM_STATE = 42\n",
    "try:\n",
    "    # Initialize Spark Session\n",
    "    spark = SparkSession.builder.appName(\"DataLoadTest\").getOrCreate()\n",
    "    \n",
    "    # Load the dataset using PySpark with default schema inference\n",
    "    df_spark_test = spark.read.csv(\n",
    "        DATA_PATH, \n",
    "        header=True, \n",
    "        inferSchema=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPySpark Inferred Schema (Note potential incorrect types or nulls):\")\n",
    "    df_spark_test.printSchema()\n",
    "    \n",
    "    print(\"\\nFirst 5 rows showing potential type conversion problems:\")\n",
    "    df_spark_test.select('rating', 'reviews', 'pages').limit(5).show()\n",
    "    \n",
    "    # Clean up the Spark session\n",
    "    spark.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not initialize or load with PySpark (PySpark may not be installed or configured): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254bc4c",
   "metadata": {},
   "source": [
    "## Important Note:\n",
    "\n",
    "As shown above and overall tested, using the dataset originally loaded using pyspark and then converting it to Pandas, causes the data to be misread and thus skews the results of the model. As shown above, certain values are in the wrong fields as well as certain values are being read as `NULL` when there is a value in that field within the dataset. Along with that, upon analysing the data and processing it, the numerical values were not converted to numerical fields and attempting to do so later in the code, does not work the way it needs to. Thus causing me to have to load the dataset using Pandas, while still keeping the pyspark code in as it is required for this POE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using pandas for robustness and explicit control\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Data loaded successfully with Pandas. Shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Check DATA_PATH.\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Display initial information\n",
    "if not df.empty:\n",
    "    print(\"\\nInitial Pandas Data Info:\")\n",
    "    df.info()\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(\"\\n\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1aef97",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Exploratory Data Analysis encompasses comprehensive investigation of dataset structure, characteristics, quality issues, and relationships between variables. This section systematically characterises the dataset through multiple complementary analytical perspectives including distributional analysis, relationship identification, and anomaly detection to inform subsequent preprocessing and feature engineering decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4c6a9",
   "metadata": {},
   "source": [
    "## Define Bestseller\n",
    "\n",
    "Best seller (in the context of a book) is a book that is among those having the largest sales during a given period.\n",
    "\n",
    "Deriving from that definition, a book with a high rating and review count would indicate popularity, thus indicating a best selling book. Using that thinking, a book is identified as a best seller based if it falls in the top 25% of both number of reviews and number of ratings, indicated by the columns `reviews` and `totalratings`.\n",
    "\n",
    "Originally it was going to be based on the `rating` of the book, then changed to the `rating` and `totalratings` but after studying the values in the dataset, it was shown that a best seller does not mean a 5 star book. \n",
    "This is proven by the book 'Fifty Shades of Grey' by E.L. James (https://www.goodreads.com/book/show/10818853-fifty-shades-of-grey)\n",
    "The book is a best seller has 2 million plus ratings, 86 thousand reviews but is only rated 3.67 (as of 30 October 2025). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of best seller in relation to the dataset, which does not contain a sales field\n",
    "df['bestseller'] = ((df['reviews'] >= df['reviews'].quantile(0.75)) & \n",
    "                    (df['totalratings'] >= df['totalratings'].quantile(0.75))).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7879b7",
   "metadata": {},
   "source": [
    "## Bestseller Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11549ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_counts = df['bestseller'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "# Count plot\n",
    "bs_counts.plot(kind='bar', ax=ax[0], color=['#FF6B6B', '#4ECDC4'])\n",
    "ax[0].set_title('Bestseller Variable Distribution', fontsize=14, fontweight='bold')\n",
    "ax[0].set_xlabel('Class (0: Non-Bestseller, 1: Bestseller)', fontsize=12)\n",
    "ax[0].set_ylabel('Count', fontsize=12)\n",
    "ax[0].tick_params(rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "ax[1].pie(bs_counts, labels=['Non-Bestseller', 'Bestseller'], \n",
    "          autopct='%1.1f%%', colors=['#FF6B6B', '#4ECDC4'], startangle=90)\n",
    "ax[1].set_title('Bestseller Variable Proportion', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974bc4f9",
   "metadata": {},
   "source": [
    "## Univariate Analysis\n",
    "Univariate analysis examines individual features independently through histograms with kernel density estimation to visualise distributional properties including modality, skewness, and outlier presence. This component-by-component investigation identifies heavily skewed distributions requiring transformation, bimodal or multimodal distributions suggesting potential data quality issues or heterogeneous populations, and extreme outliers necessitating treatment to prevent model distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94967415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns\n",
    "numerical_cols = ['rating', 'reviews', 'pages', 'totalratings']\n",
    "# Filter to only existing columns\n",
    "numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "\n",
    "# Convert to numeric if needed\n",
    "for col in numerical_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(f\"\\nNumerical Features Summary:\")\n",
    "print(df[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916664cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms and KDE plots for numerical features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    if idx < len(axes):\n",
    "        # Drop NaNs and zero values\n",
    "        col_data = df[col].dropna()\n",
    "        filtered_data = col_data[col_data != 0]\n",
    "\n",
    "        # Remove outliers (top 1%)\n",
    "        upper_limit = filtered_data.quantile(0.99)\n",
    "        filtered_data = filtered_data[filtered_data <= upper_limit]\n",
    "\n",
    "        # Plot histogram\n",
    "        ax = axes[idx]\n",
    "        filtered_data.hist(bins=50, ax=ax, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "        # KDE plot\n",
    "        ax2 = ax.twinx()\n",
    "        filtered_data.plot(kind='kde', ax=ax2, color='red', linewidth=2)\n",
    "\n",
    "        # Labels and titles\n",
    "        ax.set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel(col, fontsize=10)\n",
    "        ax.set_ylabel('Frequency', fontsize=10)\n",
    "        ax2.set_ylabel('Density', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "if 'genre' in df.columns:\n",
    "    print(f\"\\nGenre Analysis:\")\n",
    "    # Genres are often comma-separated, so let's count occurrences\n",
    "    all_genres = []\n",
    "    for genres in df['genre'].dropna():\n",
    "        all_genres.extend([g.strip() for g in str(genres).split(',')])\n",
    "\n",
    "    genre_counts = pd.Series(all_genres).value_counts().head(10)\n",
    "    print(\"Top 10 Most Common Genres:\")\n",
    "    print(genre_counts)\n",
    "\n",
    "    # Plot top genres\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    genre_counts.plot(kind='bar', color='coral')\n",
    "    plt.title('Top 10 Most Common Genres', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Genre', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Book format analysis\n",
    "if 'bookformat' in df.columns:\n",
    "    print(f\"\\nBook Format Distribution:\")\n",
    "    format_counts = df['bookformat'].value_counts()\n",
    "    print(format_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9873be6",
   "metadata": {},
   "source": [
    "## Multivariate Analysis\n",
    "Multivariate analysis investigates relationships and interactions between multiple variables through correlation matrices, heatmap visualisations, and boxplots stratified by target class. These analyses reveal feature dependencies that may indicate redundancy, identify variables exhibiting strong differential distributions between classes (suggesting high predictive power), detect potential confounding relationships, and reveal interactions not apparent in univariate examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cfa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582b380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "# Box plots: Numerical features by Bestseller class\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    if idx < len(axes):\n",
    "        df.boxplot(column=col, by='bestseller', ax=axes[idx])\n",
    "        axes[idx].set_title(f'{col} by Bestseller Class')\n",
    "        plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f\"{int(x):,}\"))\n",
    "        axes[idx].set_xlabel('Bestseller')\n",
    "        axes[idx].set_ylabel(col)\n",
    "\n",
    "plt.suptitle('Box Plots of Numerical Features by Bestseller Class')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ada1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots for better distribution visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    sns.violinplot(data=df, x='bestseller', y=col, ax=axes[idx], hue='bestseller', palette='Set2', legend=False)\n",
    "    axes[idx].set_xticks([0, 1])\n",
    "    axes[idx].set_xticklabels(['Non-Bestseller', 'Bestseller'])\n",
    "    axes[idx].set_title(f'Distribution of {col} by Bestseller')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd03ee",
   "metadata": {},
   "source": [
    "# Data Cleaning and Feature Analysis\n",
    "Comprehensive preprocessing pipeline preparation systematically addresses data quality issues through duplicate detection and removal, missing value imputation using appropriate strategies matched to feature types and statistical properties, outlier treatment using robust statistical methods like interquartile range, and feature engineering creating derived features capturing complex relationships and non-linearities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Calculate number of duplicate rows\n",
    "num_duplicates = df_processed.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "\n",
    "# Drop duplicate rows\n",
    "df_processed = df_processed.drop_duplicates()\n",
    "\n",
    "# Confirm removal\n",
    "print(f\"Shape after dropping duplicates: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3bb68",
   "metadata": {},
   "source": [
    "## Handle Missing values\n",
    "Missing value treatment employs strategy differentiation based on feature characteristics and missingness mechanisms. Numerical features undergo median imputation preserving distributional properties resistant to outlier influence. Categorical features receive mode imputation or placeholder values ('Unknown') maintaining category structure. The approach prioritises retaining information whilst maintaining data integrity and minimising model bias introduced by inappropriate imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff6ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating: fill with median\n",
    "if df_processed['rating'].isnull().sum() > 0:\n",
    "    df_processed['rating'].fillna(df_processed['rating'].median(), inplace=True)\n",
    "\n",
    "# Reviews: fill with 0 (no reviews)\n",
    "if df_processed['reviews'].isnull().sum() > 0:\n",
    "    df_processed['reviews'].fillna(0, inplace=True)\n",
    "\n",
    "# Pages: fill with median\n",
    "if df_processed['pages'].isnull().sum() > 0:\n",
    "    df_processed['pages'].fillna(df_processed['pages'].median(), inplace=True)\n",
    "\n",
    "# Total ratings: fill with 0\n",
    "if df_processed['totalratings'].isnull().sum() > 0:\n",
    "    df_processed['totalratings'].fillna(0, inplace=True)\n",
    "\n",
    "# Categorical: fill with 'Unknown'\n",
    "for col in ['author', 'genre', 'title']:\n",
    "    if col in df_processed.columns and df_processed[col].isnull().sum() > 0:\n",
    "        df_processed[col] = df_processed[col].fillna('Unknown')\n",
    "        \n",
    "df_processed = df_processed.drop(columns=['isbn', 'isbn13', 'link', 'img', 'desc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c76ff0",
   "metadata": {},
   "source": [
    "## Outlier Treatment\n",
    "Outlier detection and treatment employs the Interquartile Range (IQR) method calculating bounds from quartile measurements: lower_bound = Q1 - 1.5×IQR and upper_bound = Q3 + 1.5×IQR. Observations beyond these bounds are identified as outliers. Treatment approaches include removing extreme values, windsorising (capping at bounds), or log-transformation reducing outlier influence whilst preserving information for highly right-skewed distributions common in engagement metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Detect and report outliers\n",
    "for col in numerical_cols:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    outlier_pct = (len(outliers) / len(df)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664242f2",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Comprehensive feature engineering spans multiple categories: logarithmic transformations (`np.log1p()`) address heavily skewed distributions preserving zero values; ratio features capture relationships between variables; binning converts continuous variables into discrete categories; binary indicators create flags for specific conditions; text features extract information from string fields; and interaction features capture multiplicative relationships not evident from individual components. These engineered features often provide superior predictive power through exposing non-linear relationships and interaction effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fab0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log-transformed features for skewed distributions\n",
    "if 'reviews' in df.columns:\n",
    "    df['log_reviews'] = np.log1p(df['reviews'])  # log(1 + x) to handle zeros\n",
    "\n",
    "if 'totalratings' in df.columns:\n",
    "    df['log_totalratings'] = np.log1p(df['totalratings'])\n",
    "\n",
    "# Create title length feature\n",
    "if 'title' in df.columns:\n",
    "    df['title_length'] = df['title'].astype(str).apply(len)\n",
    "\n",
    "# Create interaction term\n",
    "if 'rating' in df.columns and 'totalratings' in df.columns:\n",
    "    df['rating_x_totalratings'] = df['rating'] * df['totalratings']\n",
    "\n",
    "# Create review engagement ratio\n",
    "if 'reviews' in df.columns and 'totalratings' in df.columns:\n",
    "    df['review_engagement_ratio'] = df['reviews'] / (df['totalratings'] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new features\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"NEW FEATURES CREATED:\")\n",
    "print(\"=\"*40)\n",
    "new_features = ['log_reviews', 'log_totalratings', 'title_length', \n",
    "                'rating_x_totalratings', 'review_engagement_ratio']\n",
    "new_features = [f for f in new_features if f in df.columns]\n",
    "print(f\"Created {len(new_features)} new features:\")\n",
    "for feature in new_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "if new_features:\n",
    "    print(\"\\nSample of new features:\")\n",
    "    print(df[new_features].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e789d",
   "metadata": {},
   "source": [
    "## Finalize Bestseller Variable\n",
    "Target variable preparation ensures consistent data type and removes any remaining inconsistencies. The target vector is extracted as a NumPy array suitable for model consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y as the Bestseller \n",
    "y = df['bestseller'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a699f89",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "Custom logistic regression implementation from first principles, incorporating gradient descent optimisation with L2 regularisation for overfitting prevention. The implementation includes probability prediction through sigmoid transformation, class label prediction with configurable threshold, loss history tracking for convergence monitoring, and coefficient extraction for feature importance interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0553a",
   "metadata": {},
   "source": [
    "## Logistical Regression Model: Model Training and Prediction\n",
    "Custom logistic regression classifier implementation using gradient descent for parameter optimisation. The sigmoid activation function transforms linear combinations into probabilities bounded within [0,1]. Binary cross-entropy loss with L2 regularisation penalty guides parameter updates. The implementation enables probability estimation and classification prediction with flexible threshold specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch:\n",
    "    \"\"\"\n",
    "    Custom Logistic Regression implementation with L2 regularization.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lr : float\n",
    "        Learning rate for gradient descent\n",
    "    epochs : int\n",
    "        Number of iterations for training\n",
    "    lambda_reg : float\n",
    "        Regularization parameter (L2)\n",
    "    verbose : bool\n",
    "        Whether to print training progress\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.01, epochs=1000, lambda_reg=0.1, verbose=True):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.verbose = verbose\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_history = []\n",
    "        self.accuracy_history = []\n",
    "        self.val_accuracy_history = []\n",
    "\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        \"\"\"\n",
    "        Sigmoid activation function: σ(z) = 1 / (1 + e^(-z))\n",
    "        \"\"\"\n",
    "        # Clip to prevent overflow\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred, weights):\n",
    "        \"\"\"\n",
    "        Compute binary cross-entropy loss with L2 regularization:\n",
    "        L = -1/m * Σ(y*log(ŷ) + (1-y)*log(1-ŷ)) + λ/(2m) * ||w||²\n",
    "        \"\"\"\n",
    "        m = len(y_true)\n",
    "        # Add small epsilon to prevent log(0)\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Binary cross-entropy\n",
    "        bce_loss = -np.mean(y_true * np.log(y_pred) + \n",
    "                           (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "        # L2 regularization term (excluding bias)\n",
    "        l2_penalty = (self.lambda_reg / (2 * m)) * np.sum(weights ** 2)\n",
    "\n",
    "        total_loss = bce_loss + l2_penalty\n",
    "        return total_loss\n",
    "\n",
    "    def compute_gradients(self, X, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute gradients for weights and bias with L2 regularization:\n",
    "        ∂L/∂w = 1/m * X^T(ŷ - y) + λ/m * w\n",
    "        ∂L/∂b = 1/m * Σ(ŷ - y)\n",
    "        \"\"\"\n",
    "        m = X.shape[0]\n",
    "        err = y_pred - y_true\n",
    "\n",
    "        # Gradient for weights (with L2 regularization)\n",
    "        dw = (1/m) * np.dot(X.T, err) + (self.lambda_reg/m) * self.weights\n",
    "\n",
    "        # Gradient for bias (no regularization on bias)\n",
    "        db = (1/m) * np.sum(err)\n",
    "\n",
    "        return dw, db\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Train the logistic regression model using gradient descent.\n",
    "        Tracks both training and (optionally) validation loss.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Training labels (0 or 1)\n",
    "        X_val : array-like, optional\n",
    "            Validation data\n",
    "        y_val : array-like, optional\n",
    "            Validation labels\n",
    "        \"\"\"\n",
    "        X, y = check_X_y(X, y)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        self.loss_history = []\n",
    "        self.val_loss_history = []\n",
    "        self.accuracy_history = []\n",
    "        self.val_accuracy_history = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            #--- Training prediction & loss ---\n",
    "            lin_out = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self.sigmoid(lin_out)\n",
    "            loss = self.compute_loss(y, y_pred, self.weights)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            # Track training accuracy\n",
    "            train_acc = np.mean((y_pred >= 0.5).astype(int) == y)\n",
    "            self.accuracy_history.append(train_acc)\n",
    "            \n",
    "            #--- Validation prediction & loss (if validation set provided) ---\n",
    "            if X_val is not None and y_val is not None:\n",
    "                linear_val = np.dot(X_val, self.weights) + self.bias\n",
    "                y_val_pred = self.sigmoid(linear_val)\n",
    "                val_loss = self.compute_loss(y_val, y_val_pred, self.weights)\n",
    "                self.val_loss_history.append(val_loss)\n",
    "                \n",
    "                # Track validation accuracy\n",
    "                val_acc = np.mean((y_val_pred >= 0.5).astype(int) == y_val)\n",
    "                self.val_accuracy_history.append(val_acc)\n",
    "\n",
    "            #--- Gradients and update ---\n",
    "            dw, db = self.compute_gradients(X, y, y_pred)\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "            if self.verbose and (epoch % 100 == 0 or epoch == self.epochs - 1):\n",
    "                acc = np.mean((y_pred >= 0.5).astype(int) == y)\n",
    "                logstr = f\"Epoch {epoch:4d}/{self.epochs} | Loss: {loss:.4f} | Accuracy: {acc:.4f}\"\n",
    "                # Print validation loss if provided\n",
    "                if X_val is not None and y_val is not None:\n",
    "                    logstr += f\" | Val Loss: {val_loss:.4f}\"\n",
    "                print(logstr)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for X.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Test data\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        prob : array, shape (n_samples,)\n",
    "            Probability of positive class\n",
    "        \"\"\"\n",
    "        X = check_array(X)\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        prob = self.sigmoid(linear_output)\n",
    "        return prob\n",
    "\n",
    "    def predict(self, X, threshold):\n",
    "        \"\"\"\n",
    "        Predict class labels for X.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Test data\n",
    "        threshold : float\n",
    "            Classification threshold\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pred : array, shape (n_samples,)\n",
    "            Predicted class labels (0 or 1)\n",
    "        \"\"\"\n",
    "        prob = self.predict_proba(X)\n",
    "        pred = (prob >= threshold).astype(int)\n",
    "        return pred\n",
    "\n",
    "    def get_coefficients(self):\n",
    "        \"\"\"\n",
    "        Get model coefficients (weights and bias).\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Dictionary containing weights and bias\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'weights': self.weights,\n",
    "            'bias': self.bias\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce528768",
   "metadata": {},
   "source": [
    "# Data Transformation Pipeline\n",
    "Feature transformations prepare data for model input through categorical encoding converting categories into numerical representations and scaling standardising feature ranges to similar magnitudes, improving convergence and preventing large-magnitude features from dominating model decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b7a7a",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "Dataset partitioning divides data into training (60%), validation (20%) and testing (20%) subsets using stratified random splitting ensuring both subsets maintain identical class distribution proportions. Stratification prevents class imbalance exacerbation in small test sets. The `random_state=42` parameter ensures reproducibility enabling consistent results across multiple executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f29d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "\n",
    "# Numerical features to include if present in dataset\n",
    "numerical_features = [\n",
    "    'rating', 'reviews', 'pages', 'totalratings',\n",
    "    'log_reviews', 'log_totalratings', 'title_length',\n",
    "    'rating_x_totalratings', 'review_engagement_ratio',\n",
    "    'is_highly_rated'\n",
    "]\n",
    "numerical_features = [f for f in numerical_features if f in df.columns]\n",
    "\n",
    "# Categorical features to encode if present in dataset\n",
    "categorical_features = ['genre']\n",
    "categorical_features = [f for f in categorical_features if f in df.columns]\n",
    "\n",
    "# Build the feature set\n",
    "all_features = numerical_features + categorical_features\n",
    "X = df[all_features]\n",
    "\n",
    "# Replace inf/-inf with large numbers for safety, and fill NaNs\n",
    "X = X.replace([np.inf, -np.inf], [1e10, -1e10]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d969b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train+val and test first\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then split train+val into train and val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape:   {X_val.shape}\")\n",
    "print(f\"X_test shape:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81dfbc3",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "Categorical feature encoding transforms categorical variables into numerical representations through one-hot encoding creating binary indicator variables for each category with `drop_first=True` avoiding the dummy variable trap causing multicollinearity. This process standardises feature space for model consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [col for col in categorical_features if \n",
    "                        col in X_train.columns and col in X_val.columns and col in X_test.columns]\n",
    "\n",
    "if categorical_features:\n",
    "    # Clean up text in categorical columns\n",
    "    for col in categorical_features:\n",
    "        X_train[col] = X_train[col].astype(str).str.split(',').str[0].str.strip()\n",
    "        X_val[col] = X_val[col].astype(str).str.split(',').str[0].str.strip()\n",
    "        X_test[col] = X_test[col].astype(str).str.split(',').str[0].str.strip()\n",
    "\n",
    "    # Filter only low-cardinality features\n",
    "    low_cardinality = [col for col in categorical_features if X_train[col].nunique() <= 50]\n",
    "\n",
    "    if low_cardinality:\n",
    "        # Encode and align\n",
    "        X_train_enc = pd.get_dummies(X_train[low_cardinality], drop_first=True)\n",
    "        X_val_enc = pd.get_dummies(X_val[low_cardinality], drop_first=True)\n",
    "        X_test_enc = pd.get_dummies(X_test[low_cardinality], drop_first=True)\n",
    "\n",
    "        # Align columns across all three sets\n",
    "        X_train_enc, X_val_enc = X_train_enc.align(X_val_enc, join='left', axis=1, fill_value=0)\n",
    "        X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join='left', axis=1, fill_value=0)\n",
    "        X_val_enc, X_test_enc = X_val_enc.align(X_test_enc, join='left', axis=1, fill_value=0)\n",
    "\n",
    "        # Drop original categorical columns\n",
    "        X_train = X_train.drop(columns=low_cardinality)\n",
    "        X_val = X_val.drop(columns=low_cardinality)\n",
    "        X_test = X_test.drop(columns=low_cardinality)\n",
    "\n",
    "        # Concatenate encoded columns back\n",
    "        X_train = pd.concat([X_train.reset_index(drop=True), X_train_enc.reset_index(drop=True)], axis=1)\n",
    "        X_val = pd.concat([X_val.reset_index(drop=True), X_val_enc.reset_index(drop=True)], axis=1)\n",
    "        X_test = pd.concat([X_test.reset_index(drop=True), X_test_enc.reset_index(drop=True)], axis=1)\n",
    "        \n",
    "    X_train = X_train.select_dtypes(exclude=['object'])\n",
    "    X_val = X_val.select_dtypes(exclude=['object'])\n",
    "    X_test = X_test.select_dtypes(exclude=['object'])\n",
    "else:\n",
    "    print(\"No categorical features to encode.\")\n",
    "\n",
    "# After encoding, assert only numerics remain\n",
    "assert X_train.select_dtypes(include='object').shape[1] == 0, \"Non-numeric columns remain after encoding!\"\n",
    "assert X_val.select_dtypes(include='object').shape[1] == 0, \"Non-numeric columns remain after encoding!\"\n",
    "assert X_test.select_dtypes(include='object').shape[1] == 0, \"Non-numeric columns remain after encoding!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_values = X_train.values\n",
    "X_val_values = X_val.values\n",
    "X_test_values = X_test.values\n",
    "\n",
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e7a5a",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Feature scaling using RobustScaler standardises feature ranges through robust statistical transformations (median centering and Interquartile Range normalisation) less sensitive to outliers than standard scaling. The scaler is fit exclusively on training data preventing data leakage, then applied identically to validation and test sets maintaining distributional consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RobustScaler (less sensitive to outliers than StandardScaler)\n",
    "scaler = RobustScaler()\n",
    "\n",
    "print(\"Fitting scaler on training data...\")\n",
    "# Fit scaler on training data ONLY\n",
    "scaler.fit(X_train_values)\n",
    "\n",
    "# Transform train, validation, and test data\n",
    "X_train_scaled = scaler.transform(X_train_values)\n",
    "X_val_scaled = scaler.transform(X_val_values)\n",
    "X_test_scaled = scaler.transform(X_test_values)\n",
    "\n",
    "print(f\"\\nScaled data shapes:\")\n",
    "print(f\"X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"X_val_scaled:   {X_val_scaled.shape}\")\n",
    "print(f\"X_test_scaled:  {X_test_scaled.shape}\")\n",
    "\n",
    "# Display scaling statistics\n",
    "print(f\"\\nScaling statistics (from training data):\")\n",
    "print(f\"Median (center) - first 5 features: {scaler.center_[:5]}\")\n",
    "print(f\"IQR (scale) - first 5 features: {scaler.scale_[:5]}\")\n",
    "\n",
    "# Verify scaling worked\n",
    "print(f\"\\nTraining data after scaling:\")\n",
    "print(f\"Mean: {X_train_scaled.mean(axis=0)[:5]}\")  # Should be close to 0\n",
    "print(f\"Std: {X_train_scaled.std(axis=0)[:5]}\")    # Should be close to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a8f5aa",
   "metadata": {},
   "source": [
    "# Initial Model Training and Evaluation\n",
    "Training and evaluation phase establishing baseline performance metrics before hyperparameter optimisation. This phase trains a model with preliminary hyperparameters and comprehensively evaluates performance across training and test datasets using multiple metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe2769",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Model instantiation and training with preliminary hyperparameters establishes baseline learning behaviour. The verbose output enables real-time loss monitoring facilitating convergence assessment and identification of training issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with preliminary hyperparameters\n",
    "initial_model = LogisticRegressionScratch(\n",
    "    lr=0.01,\n",
    "    epochs=1000,\n",
    "    lambda_reg=0.1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining model with preliminary hyperparameters:\")\n",
    "print(f\"  Learning Rate: {initial_model.lr}\")\n",
    "print(f\"  Epochs: {initial_model.epochs}\")\n",
    "print(f\"  Regularization (λ): {initial_model.lambda_reg}\")\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Train the model\n",
    "initial_model.fit(X_train_scaled, y_train, X_val=X_val_scaled, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816372ae",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "Prediction generation produces both class labels and probability estimates on training and test datasets enabling comprehensive performance evaluation across multiple perspectives and threshold operating points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on both training and validation sets\n",
    "y_train_pred_initial = initial_model.predict(X_train_scaled, threshold=0.5)\n",
    "y_val_pred_initial = initial_model.predict(X_val_scaled, threshold=0.5)\n",
    "y_pred_initial = initial_model.predict(X_test_scaled, threshold=0.5)\n",
    "\n",
    "# Get probabilities for ROC-AUC calculation\n",
    "y_train_proba_initial = initial_model.predict_proba(X_train_scaled)\n",
    "y_val_proba_initial = initial_model.predict_proba(X_val_scaled)\n",
    "y_proba_initial = initial_model.predict_proba(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539656fc",
   "metadata": {},
   "source": [
    "## Initial Evaluation\n",
    "Initial performance assessment computes classification metrics including accuracy, precision, recall, F1-score, and ROC AUC across training and test sets. These metrics establish baseline performance for comparison against optimised models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62645d37",
   "metadata": {},
   "source": [
    "### Training vs Validation\n",
    "Comparative assessment of training versus validation performance identifies potential overfitting or underfitting. Training performance substantially exceeding test performance indicates overfitting requiring regularisation strengthening or model simplification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aed451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate metrics for training set\n",
    "train_accuracy_initial = accuracy_score(y_train, y_train_pred_initial)\n",
    "train_precision_initial = precision_score(y_train, y_train_pred_initial, zero_division=0)\n",
    "train_recall_initial = recall_score(y_train, y_train_pred_initial, zero_division=0)\n",
    "train_f1_initial = f1_score(y_train, y_train_pred_initial, zero_division=0)\n",
    "train_roc_auc_initial = roc_auc_score(y_train, y_train_proba_initial)\n",
    "\n",
    "# Calculate metrics for validation set\n",
    "val_accuracy_initial = accuracy_score(y_val, y_val_pred_initial)\n",
    "val_precision_initial = precision_score(y_val, y_val_pred_initial, zero_division=0)\n",
    "val_recall_initial = recall_score(y_val, y_val_pred_initial, zero_division=0)\n",
    "val_f1_initial = f1_score(y_val, y_val_pred_initial, zero_division=0)\n",
    "val_roc_auc_initial = roc_auc_score(y_val, y_val_proba_initial)\n",
    "\n",
    "# Print individual metrics for clarity\n",
    "print(\"\\nINDIVIDUAL TRAINING SET METRICS:\")\n",
    "print(f\"  Accuracy:  {train_accuracy_initial:.4f}\")\n",
    "print(f\"  Precision: {train_precision_initial:.4f}\")\n",
    "print(f\"  Recall:    {train_recall_initial:.4f}\")\n",
    "print(f\"  F1-Score:  {train_f1_initial:.4f}\")\n",
    "print(f\"  ROC AUC:   {train_roc_auc_initial:.4f}\")\n",
    "\n",
    "print(\"\\nINDIVIDUAL VALIDATION SET METRICS:\")\n",
    "print(f\"  Accuracy:  {val_accuracy_initial:.4f}\")\n",
    "print(f\"  Precision: {val_precision_initial:.4f}\")\n",
    "print(f\"  Recall:    {val_recall_initial:.4f}\")\n",
    "print(f\"  F1-Score:  {val_f1_initial:.4f}\")\n",
    "print(f\"  ROC AUC:   {val_roc_auc_initial:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94911d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(initial_model.loss_history) + 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# LOSS CURVE\n",
    "axes[0].plot(epochs, initial_model.loss_history, label='Training Loss', color='#2E86AB')\n",
    "if hasattr(initial_model, 'val_loss_history') and len(initial_model.val_loss_history) > 0:\n",
    "    axes[0].plot(epochs, initial_model.val_loss_history, label='Validation Loss', color='#A23B72')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training vs Validation Loss (Curve)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# ACCURACY CURVE\n",
    "if hasattr(initial_model, 'accuracy_history') and len(initial_model.accuracy_history) > 0:\n",
    "    axes[1].plot(epochs, initial_model.accuracy_history, label='Training Accuracy', color='#2E86AB')\n",
    "if hasattr(initial_model, 'val_accuracy_history') and len(initial_model.val_accuracy_history) > 0:\n",
    "    axes[1].plot(epochs, initial_model.val_accuracy_history, label='Validation Accuracy', color='#A23B72')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training vs Validation Accuracy (Curve)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282382a",
   "metadata": {},
   "source": [
    "### Initial Model \n",
    "Test set evaluation provides unbiased performance assessment on previously unseen data representing true generalisation capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb30d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_initial = accuracy_score(y_test, y_pred_initial)\n",
    "precision_initial = precision_score(y_test, y_pred_initial, zero_division=0)\n",
    "recall_initial = recall_score(y_test, y_pred_initial, zero_division=0)\n",
    "f1_initial = f1_score(y_test, y_pred_initial, zero_division=0)\n",
    "roc_auc_initial = roc_auc_score(y_test, y_proba_initial)\n",
    "\n",
    "print(\"INITIAL MODEL PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  Accuracy:  {accuracy_initial:.4f}\")\n",
    "print(f\"  Precision: {precision_initial:.4f}\")\n",
    "print(f\"  Recall:    {recall_initial:.4f}\")\n",
    "print(f\"  F1-Score:  {f1_initial:.4f}\")\n",
    "print(f\"  ROC AUC:   {roc_auc_initial:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_initial = confusion_matrix(y_test, y_pred_initial)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_initial)\n",
    "print(\"\\nConfusion Matrix Breakdown:\")\n",
    "tn, fp, fn, tp = cm_initial.ravel()\n",
    "print(f\"  True Negatives (TN):  {tn}\")\n",
    "print(f\"  False Positives (FP): {fp}\")\n",
    "print(f\"  False Negatives (FN): {fn}\")\n",
    "print(f\"  True Positives (TP):  {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d32ca",
   "metadata": {},
   "source": [
    "## The graphs below are based on the initial model's results from the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa76047",
   "metadata": {},
   "source": [
    "## Confusion Matrix Visualisation\n",
    "Confusion matrix presentation through annotated heatmap visualisation clearly shows true positives, true negatives, false positives, and false negatives enabling intuitive understanding of classification performance and error patterns across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f142b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_initial = confusion_matrix(y_test, y_pred_initial)\n",
    "\n",
    "# Visualize confusion matrix,\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_initial, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Non-Bestseller', 'Bestseller'],\n",
    "            yticklabels=['Non-Bestseller', 'Bestseller'])\n",
    "plt.title('Initial Model - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix Values:\")\n",
    "print(f\"Initial Model Set TP: {cm_initial[1,1]}, TN: {cm_initial[0,0]}, FP: {cm_initial[0,1]}, FN: {cm_initial[1,0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3fbfe6",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "Final per-class performance metrics demonstrating comprehensive model effectiveness across both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77dbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_pred_initial, target_names=['Not Bestseller', 'Bestseller']))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a06ba",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "Final ROC curve and AUC visualisation assessing discrimination ability on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve\n",
    "fpr_initial, tpr_initial, roc_thresholds_initial = roc_curve(y_test, y_proba_initial)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_initial, tpr_initial, label=f'ROC Curve (AUC = {roc_auc_initial:.3f})', \n",
    "         color='purple', linewidth=3)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Initial Model: ROC Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630a6be",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve\n",
    "Final precision-recall curve demonstrating performance characteristics particularly relevant for imbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db88827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision-Recall curve\n",
    "precision_curve_initial, recall_curve_initial, pr_thresholds = precision_recall_curve(y_test, y_proba_initial)\n",
    "# Calculate average precision\n",
    "avg_precision_initial = average_precision_score(y_test, y_proba_initial)\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_curve_initial, precision_curve_initial, label=f'Precision-Recall Curve ({avg_precision_initial:.3f})', \n",
    "         color='darkorange', linewidth=3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Initial Model: Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage Precision Score: {avg_precision_initial:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29bea03",
   "metadata": {},
   "source": [
    "## Training Loss Curve\n",
    "Final loss curve visualisation demonstrating convergence of optimised model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(initial_model.loss_history, linewidth=2, color='blue')\n",
    "plt.title('Initial Model - Training Loss Curve', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c23f8",
   "metadata": {},
   "source": [
    "# Model Improvements and Retraining\n",
    "Optimisation phase systematically improving model performance through hyperparameter tuning, class imbalance mitigation, and iterative retraining with refined parameters based on cross-validation performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac846812",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "Hyperparameter search space definition specifies parameter ranges to explore: learning rates controlling optimisation step sizes, L2 regularisation coefficients controlling overfitting penalty strength, and iteration counts controlling training epochs. Systematic grid search exhaustively evaluates all parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cd101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_scratch(model_class, X, y, params, cv=5):\n",
    "    \"\"\"\n",
    "    Cross-validation for custom model. Returns list of scores for F1 metric.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
    "        y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Train model\n",
    "        model = model_class(**params, verbose=False)\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred_cv = model.predict(X_val_cv, threshold=0.5)\n",
    "        score = f1_score(y_val_cv, y_pred_cv, zero_division=0)\n",
    "        scores.append(score)\n",
    "\n",
    "        if fold == 0:  # Print first fold details\n",
    "            print(f\"  Fold 1 - F1 Score: {score:.4f}\")\n",
    "\n",
    "    return scores\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.01, 0.05],\n",
    "    'lambda_reg': [0.01, 0.1, 1.0],\n",
    "    'epochs': [500, 1000, 2000]\n",
    "}\n",
    "\n",
    "print(\"\\nParameter Grid:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "total_combinations = len(param_grid['lr']) * len(param_grid['lambda_reg']) * len(param_grid['epochs'])\n",
    "print(f\"\\nTotal parameter combinations to test: {total_combinations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9994839d",
   "metadata": {},
   "source": [
    "## Grid Search Execution\n",
    "Grid search with cross-validation systematically evaluates all hyperparameter combinations across stratified folds computing F1-score as primary evaluation metric. Best parameters maximising cross-validation F1-score are selected for final model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bba2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Grid Search\n",
    "params_product = list(product(param_grid['lr'], param_grid['lambda_reg'], param_grid['epochs']))\n",
    "best_score = 0\n",
    "best_params = None\n",
    "cv_results = []\n",
    "\n",
    "print(\"\\nRunning grid search with 5-fold cross-validation...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, (lr, lambda_reg, epochs) in enumerate(params_product):\n",
    "    params = {\n",
    "        'lr': lr,\n",
    "        'lambda_reg': lambda_reg,\n",
    "        'epochs': epochs\n",
    "    }\n",
    "\n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score_scratch(LogisticRegressionScratch, X_train_scaled, y_train, params)\n",
    "    mean_score = np.mean(scores)\n",
    "    std_score = np.std(scores)\n",
    "\n",
    "    cv_results.append({\n",
    "        'params': params,\n",
    "        'mean_f1': mean_score,\n",
    "        'std_f1': std_score,\n",
    "        'all_scores': scores\n",
    "    })\n",
    "\n",
    "    print(f\"Config {i+1:2d}/{total_combinations}: lr={lr:.3f}, λ={lambda_reg:.2f}, epochs={epochs:4d} | \"\n",
    "          f\"F1: {mean_score:.4f} (±{std_score:.4f})\")\n",
    "\n",
    "    # Track best parameters\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BEST HYPERPARAMETERS FOUND:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Learning Rate: {best_params['lr']}\")\n",
    "print(f\"Regularization (λ): {best_params['lambda_reg']}\")\n",
    "print(f\"Epochs: {best_params['epochs']}\")\n",
    "print(f\"Best mean F1-score (CV): {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec49470",
   "metadata": {},
   "source": [
    "## Bias-Variance Analysis\n",
    "Learning curve analysis examining training and validation performance across increasing training set sizes diagnoses model complexity issues. Converging training and validation curves at high performance indicate good model fit. Diverging curves indicate overfitting or underfitting requiring corrective action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with best parameters to analyze learning curves\n",
    "print(\"Training model with best parameters for learning curve analysis...\")\n",
    "final_model = LogisticRegressionScratch(**best_params, verbose=True)\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Analyze convergence\n",
    "final_loss = final_model.loss_history[-1]\n",
    "initial_loss = final_model.loss_history[0]\n",
    "loss_reduction = (initial_loss - final_loss) / initial_loss * 100\n",
    "\n",
    "print(f\"\\nLoss Analysis:\")\n",
    "print(f\"  Initial Loss: {initial_loss:.4f}\")\n",
    "print(f\"  Final Loss: {final_loss:.4f}\")\n",
    "print(f\"  Loss Reduction: {loss_reduction:.1f}%\")\n",
    "\n",
    "# Check for convergence in last 100 epochs\n",
    "if len(final_model.loss_history) >= 100:\n",
    "    last_100_losses = final_model.loss_history[-100:]\n",
    "    loss_std = np.std(last_100_losses)\n",
    "    if loss_std < 0.001:\n",
    "        print(\" Status: Model converged (loss stabilized)\")\n",
    "    else:\n",
    "        print(\" Status: Model may benefit from more epochs\")\n",
    "else:\n",
    "    print(\" Status: Model trained for fewer than 100 epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae9f75",
   "metadata": {},
   "source": [
    "## Class Imbalance Mitigation\n",
    "Class imbalance analysis quantifying training set class distribution informs mitigation strategy selection. Severe imbalance (e.g., 80-20 split) requires resampling through oversampling minority class or undersampling majority class to improve model fairness and minority class performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74cb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original training set distribution:\")\n",
    "original_counts = np.bincount(y_train)\n",
    "print(f\"  Class 0: {original_counts[0]} ({original_counts[0]/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Class 1: {original_counts[1]} ({original_counts[1]/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# Apply SMOTE to training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nResampled training set:\")\n",
    "print(f\"  Original size: {X_train_scaled.shape[0]} samples\")\n",
    "print(f\"  Resampled size: {X_train_resampled.shape[0]} samples\")\n",
    "\n",
    "resampled_counts = np.bincount(y_train_resampled)\n",
    "print(f\"\\nResampled class distribution:\")\n",
    "print(f\"  Class 0: {resampled_counts[0]} ({resampled_counts[0]/len(y_train_resampled)*100:.1f}%)\")\n",
    "print(f\"  Class 1: {resampled_counts[1]} ({resampled_counts[1]/len(y_train_resampled)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689bff1",
   "metadata": {},
   "source": [
    "## Final Model Training (with Resampled Data)\n",
    "Final model training using optimal hyperparameters and balanced training data through resampling. This model incorporates all improvements from previous phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_resampled = LogisticRegressionScratch(**best_params, verbose=True)\n",
    "final_model_resampled.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076e24c4",
   "metadata": {},
   "source": [
    "# Final Evaluation and Interpretation\n",
    "Comprehensive final evaluation of optimised model examining predictions, performance metrics, and feature importance across all evaluation perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4fcf2",
   "metadata": {},
   "source": [
    "## Final Model Predictions and Threshold Optimization\n",
    "Probability prediction and threshold optimisation selecting classification threshold maximising F1-score rather than assuming default 0.5 threshold. Threshold optimisation accommodates specific business requirements and class imbalance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for the positive class\n",
    "y_pred_proba_final = final_model_resampled.predict_proba(X_test_scaled)\n",
    "\n",
    "# Find optimal threshold based on F1 score\n",
    "f1_scores_by_threshold = []\n",
    "thresholds_to_test = np.arange(0.1, 0.9, 0.05)\n",
    "# Created to metrics for each threshold \n",
    "results = []\n",
    "\n",
    "best_threshold = 0.5\n",
    "best_f1_threshold = 0.0\n",
    "\n",
    "for threshold in thresholds_to_test:\n",
    "    y_pred_thresh = (y_pred_proba_final >= threshold).astype(int)\n",
    "    f1_thresh = f1_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    precision_thresh = precision_score(y_test, y_pred_thresh, zero_division=0)\n",
    "    recall_thresh = recall_score(y_test, y_pred_thresh, zero_division=0)\n",
    "\n",
    "    f1_scores_by_threshold.append(f1_thresh)\n",
    "    \n",
    "    # Will be used for Visualisation of Threshold Optimizations Visualization\n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'f1_score': f1_thresh,\n",
    "        'precision': precision_thresh,\n",
    "        'recall': recall_thresh\n",
    "    })\n",
    "    \n",
    "    if f1_thresh > best_f1_threshold:\n",
    "        best_f1_threshold = f1_thresh\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\n Optimal threshold for F1-Score: {best_threshold:.2f}\")\n",
    "print(f\"   Best F1-Score achieved: {best_f1_threshold:.4f}\")\n",
    "\n",
    "# Make predictions using optimal threshold\n",
    "y_pred_final = (y_pred_proba_final >= best_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nFinal model predictions using optimal threshold:\")\n",
    "print(f\"  Predictions shape: {y_pred_final.shape}\")\n",
    "print(f\"  Probability range: [{y_pred_proba_final.min():.3f}, {y_pred_proba_final.max():.3f}]\")\n",
    "print(f\"  Predicted classes: {np.unique(y_pred_final)}\")\n",
    "\n",
    "# Count predicted classes\n",
    "final_pred_counts = np.bincount(y_pred_final)\n",
    "print(f\"\\nFinal prediction distribution:\")\n",
    "print(f\"  Predicted Non-Bestsellers: {final_pred_counts[0]} ({final_pred_counts[0]/len(y_pred_final)*100:.1f}%)\")\n",
    "print(f\"  Predicted Bestsellers: {final_pred_counts[1]} ({final_pred_counts[1]/len(y_pred_final)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33093eae",
   "metadata": {},
   "source": [
    "## Final Metrics Calculation\n",
    "Final performance metrics computation across test set using optimised threshold quantifying model generalisation capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fac8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_final = accuracy_score(y_test, y_pred_final) \n",
    "precision_final = precision_score(y_test, y_pred_final, zero_division=0) \n",
    "recall_final = recall_score(y_test, y_pred_final, zero_division=0) \n",
    "f1_final = f1_score(y_test, y_pred_final, zero_division=0) \n",
    "roc_auc_final = roc_auc_score(y_test, y_pred_proba_final)\n",
    "\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(f\"  Accuracy:  {accuracy_final:.4f}\")\n",
    "print(f\"  Precision: {precision_final:.4f}\")\n",
    "print(f\"  Recall:    {recall_final:.4f}\")\n",
    "print(f\"  F1-Score:  {f1_final:.4f}\")\n",
    "print(f\"  ROC AUC:   {roc_auc_final:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_final = confusion_matrix(y_test, y_pred_final)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_final)\n",
    "print(\"\\nConfusion Matrix Breakdown:\")\n",
    "tn, fp, fn, tp = cm_final.ravel()\n",
    "print(f\"  True Negatives (TN):  {tn}\")\n",
    "print(f\"  False Positives (FP): {fp}\")\n",
    "print(f\"  False Negatives (FN): {fn}\")\n",
    "print(f\"  True Positives (TP):  {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b2a2d",
   "metadata": {},
   "source": [
    "## Confusion Matrix Visualization\n",
    "Final confusion matrix presentation showing classification performance on test set with optimised threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4208cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_final, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-Bestseller', 'Bestseller'],\n",
    "            yticklabels=['Non-Bestseller', 'Bestseller'])\n",
    "plt.title('Final Model - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d892b9",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "Final per-class performance metrics demonstrating comprehensive model effectiveness across both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ccbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_final, \n",
    "                          target_names=['Non-Bestseller', 'Bestseller']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af2782",
   "metadata": {},
   "source": [
    "## ROC Curve\n",
    "Final ROC curve and AUC visualisation assessing discrimination ability on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b712c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve\n",
    "fpr_final, tpr_final, roc_thresholds_final = roc_curve(y_test, y_pred_proba_final)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_final, tpr_final, label=f'ROC Curve (AUC = {roc_auc_final:.3f})', \n",
    "         color='purple', linewidth=3)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Final Model: ROC Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7369bb1a",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve\n",
    "Final precision-recall curve demonstrating performance characteristics particularly relevant for imbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9637bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision-Recall curve\n",
    "precision_curve_final, recall_curve_final, pr_thresholds = precision_recall_curve(y_test, y_pred_proba_final)\n",
    "# Calculate average precision\n",
    "avg_precision_final = average_precision_score(y_test, y_pred_proba_final)\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_curve_final, precision_curve_final, label=f'Precision-Recall Curve ({avg_precision_final:.3f})', \n",
    "         color='darkorange', linewidth=3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Final Model: Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"\\nAverage Precision Score: {avg_precision_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9e958",
   "metadata": {},
   "source": [
    "## Training Loss Curve\n",
    "Final loss curve visualisation demonstrating convergence of optimised model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(final_model.loss_history, linewidth=2, color='green')\n",
    "plt.title('Final Model - Training Loss Curve', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa52c05",
   "metadata": {},
   "source": [
    "## Threshold Optimization Visualization\n",
    "Threshold optimisation results visualisation showing F1-score variation across probability thresholds, demonstrating threshold selection rationale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457faf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Visualize the threshold optimization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['threshold'], results_df['f1_score'], marker='o', label='F1-Score')\n",
    "plt.plot(results_df['threshold'], results_df['precision'], marker='s', label='Precision')\n",
    "plt.plot(results_df['threshold'], results_df['recall'], marker='^', label='Recall')\n",
    "plt.xlabel('Classification Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Metrics vs Classification Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c56f1",
   "metadata": {},
   "source": [
    "# Initial and Final Model Comparison and Evaluation\n",
    "Comparative analysis between initial baseline and optimised final model quantifying improvements across all metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f577b",
   "metadata": {},
   "source": [
    "## Model Comparison Table\n",
    "Summary table juxtaposing initial and final model metrics enabling rapid visual comparison of improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Initial Model': [accuracy_initial, precision_initial, recall_initial, f1_initial, roc_auc_initial],\n",
    "    'Final Model': [accuracy_final, precision_final, recall_final, f1_final, roc_auc_final],\n",
    "    'Improvement': [accuracy_final-accuracy_initial, precision_final-precision_initial, \n",
    "                   recall_final-recall_initial, f1_final-f1_initial, roc_auc_final-roc_auc_initial]\n",
    "}, index=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC'])\n",
    "\n",
    "print(\"\\nDetailed Model Comparison:\")\n",
    "print(metrics_comparison.round(4))\n",
    "\n",
    "# Determine best improvements\n",
    "improvements = metrics_comparison['Improvement']\n",
    "best_improvement = improvements.idxmax()\n",
    "worst_improvement = improvements.idxmin()\n",
    "\n",
    "print(f\"\\n Best Improvement: {best_improvement} (+{improvements[best_improvement]:.4f})\")\n",
    "print(f\" Worst Change: {worst_improvement} ({improvements[worst_improvement]:+.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb69f92",
   "metadata": {},
   "source": [
    "## Comparitive Charts\n",
    "Bar chart visualisation comparing model metrics side-by-side across accuracy, precision, recall, F1-score, and ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed7eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC']\n",
    "original = [accuracy_initial, precision_initial, recall_initial, f1_initial, roc_auc_initial]\n",
    "final = [accuracy_final, precision_final, recall_final, f1_final, roc_auc_final]\n",
    "\n",
    "# Side-by-side bar chart\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x - width/2, original, width, label='Original', color='lightblue')\n",
    "plt.bar(x + width/2, final, width, label='Final', color='orange')\n",
    "plt.xticks(x, metrics)\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.title('Model Performance: Original vs Final')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Delta bar chart\n",
    "deltas = [f - o for o, f in zip(original, final)]\n",
    "colors = ['green' if d > 0 else 'red' for d in deltas]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(metrics, deltas, color=colors)\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.ylabel('Change (Δ)')\n",
    "plt.title('Change in Model Performance After Retraining')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b3caa",
   "metadata": {},
   "source": [
    "## Curve Comparisons\n",
    "Superimposed curve comparison showing initial versus final model performance across ROC and precision-recall curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3014f",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "ROC curve comparison demonstrating discriminative ability improvement from initial to final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd75ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Initial vs Final ROC Curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_initial, tpr_initial, color='blue', lw=2, \n",
    "         label=f'Initial ROC (AUC = {roc_auc_initial:.3f})')\n",
    "plt.plot(fpr_final, tpr_final, color='orange', lw=2, \n",
    "         label=f'Final ROC (AUC = {roc_auc_final:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "         label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve: Initial vs Final Comparison')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nROC-AUC Initial: {roc_auc_initial:.4f}\")\n",
    "print(f\"ROC-AUC Final:  {roc_auc_final:.4f}\")\n",
    "print(f\"AUC Gap:       {abs(roc_auc_initial - roc_auc_final):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016edd3",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve\n",
    "Precision-recall curve comparison showing performance improvement particularly relevant for imbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52634618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Initial vs Final Precision-Recall Curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall_curve_initial, precision_curve_initial, color='blue', lw=2, \n",
    "         label=f'Initial PR (AP = {avg_precision_initial:.3f})')\n",
    "plt.plot(recall_curve_final, precision_curve_final, color='orange', lw=2, \n",
    "         label=f'Final PR (AP = {avg_precision_final:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve: Initial vs Final Comparison')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage Precision Initial: {avg_precision_initial:.4f}\")\n",
    "print(f\"Average Precision Final:  {avg_precision_final:.4f}\")\n",
    "print(f\"AP Gap:                  {abs(avg_precision_initial - avg_precision_final):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de1199",
   "metadata": {},
   "source": [
    "## Feature Interpretation\n",
    "Feature coefficient analysis ranking features by magnitude and sign interpretation. Positive coefficients increase predicted probability of target=True whilst negative coefficients decrease it. Coefficient magnitudes reflect feature importance in model decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de196740",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': final_model_resampled.get_coefficients()['weights'],\n",
    "    'Abs_Coefficient': np.abs(final_model_resampled.get_coefficients()['weights'])\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance (by coefficient magnitude) ===\")\n",
    "print(coefficients)\n",
    "\n",
    "# Visualize top features\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_n = min(15, len(coefficients))\n",
    "top_features = coefficients.head(top_n)\n",
    "\n",
    "# Color: green if positive, red if negative\n",
    "colors = ['green' if x > 0 else 'red' for x in top_features['Coefficient']]\n",
    "\n",
    "plt.barh(range(top_n), top_features['Coefficient'], color=colors)\n",
    "plt.yticks(range(top_n), top_features['Feature'])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Top Feature Coefficients (Green=Positive, Red=Negative)')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe63d6",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Dictionary.com. (2023). Dictionary.com | Meanings & Definitions of English Words. [online] Available at: https://www.dictionary.com/browse/bestseller [Accessed 30 Oct. 2025].\n",
    "\n",
    "‌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
